{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling and Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 120542 points in our data set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alex Brosas another idiot #ALDUBKSGoesToUS  ht...</td>\n",
       "      <td>alex brosas idiot aldubksgoestous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @ItIzBiz: as Nancy Reagan would say, 'just ...</td>\n",
       "      <td>nancy reagan fucking like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @MailOnline: The Nazi death gas so horrific...</td>\n",
       "      <td>nazi death gas horrific hitler fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I hate er chase because if the Bitch that work...</td>\n",
       "      <td>hate er chase bitch work literally evil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @chevleia: don't hmu when u get tired of ur...</td>\n",
       "      <td>hmu tired ur bore hoe ur bore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet  \\\n",
       "0      0  Alex Brosas another idiot #ALDUBKSGoesToUS  ht...   \n",
       "1      0  RT @ItIzBiz: as Nancy Reagan would say, 'just ...   \n",
       "2      0  RT @MailOnline: The Nazi death gas so horrific...   \n",
       "3      1  I hate er chase because if the Bitch that work...   \n",
       "4      0  RT @chevleia: don't hmu when u get tired of ur...   \n",
       "\n",
       "                               clean_tweet  \n",
       "0        alex brosas idiot aldubksgoestous  \n",
       "1                nancy reagan fucking like  \n",
       "2      nazi death gas horrific hitler fear  \n",
       "3  hate er chase bitch work literally evil  \n",
       "4            hmu tired ur bore hoe ur bore  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv('data/clean_data.csv', lineterminator='\\n')\n",
    "print(f'There are currently {len(df)} points in our data set.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our subsample has 30135 data points.\n",
      "The training split of the subsample has 24108 data points.\n",
      "The test split of the subsample has 6027 data points.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into features and target label \n",
    "X = df.clean_tweet\n",
    "y = df.label\n",
    "\n",
    "# Get smaller subset of the data\n",
    "# NOTE: Since the classes are imbalanced, we use a stratified random split \n",
    "X_small, X_big, y_small, y_big = train_test_split(X, y, stratify=y, test_size=0.75)\n",
    "print(f'Our subsample has {len(X_small)} data points.')\n",
    "\n",
    "# Split subsample into training and test sets. \n",
    "# Once again, we use a stratified split. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_small, y_small, stratify=y_small, test_size=0.2)\n",
    "print(f'The training split of the subsample has {len(X_train)} data points.')\n",
    "print(f'The test split of the subsample has {len(X_test)} data points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "{'bow__ngram_range': (1, 2), 'model__C': 0.01, 'model__class_weight': None, 'model__penalty': 'none', 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      5613\n",
      "           1       0.50      0.32      0.39       414\n",
      "\n",
      "    accuracy                           0.93      6027\n",
      "   macro avg       0.73      0.65      0.68      6027\n",
      "weighted avg       0.92      0.93      0.92      6027\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "{'bow__ngram_range': (1, 2), 'model__alpha': 0.5, 'model__fit_prior': False, 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      5613\n",
      "           1       0.42      0.38      0.40       414\n",
      "\n",
      "    accuracy                           0.92      6027\n",
      "   macro avg       0.69      0.67      0.68      6027\n",
      "weighted avg       0.92      0.92      0.92      6027\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "{'bow__ngram_range': (1, 1), 'model__ccp_alpha': 0, 'model__class_weight': 'balanced', 'model__n_estimators': 100, 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      5613\n",
      "           1       0.71      0.21      0.32       414\n",
      "\n",
      "    accuracy                           0.94      6027\n",
      "   macro avg       0.83      0.60      0.65      6027\n",
      "weighted avg       0.93      0.94      0.92      6027\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "{'bow__ngram_range': (1, 1), 'model__eta': 0.6, 'model__max_depth': 10, 'model__scale_pos_weight': 10, 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      5613\n",
      "           1       0.41      0.49      0.44       414\n",
      "\n",
      "    accuracy                           0.92      6027\n",
      "   macro avg       0.68      0.72      0.70      6027\n",
      "weighted avg       0.92      0.92      0.92      6027\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of potential models to try out with different parameters\n",
    "model_list = [\n",
    "    (LogisticRegression(solver='saga'), {\n",
    "        'model__penalty' : ['l1', 'l2', 'none'],\n",
    "        'model__C' : [0.01, 0.1, 1],\n",
    "        'model__class_weight' : ['balanced', None],      \n",
    "    }),\n",
    "    (MultinomialNB(), {\n",
    "        'model__fit_prior': [True, False],\n",
    "        'model__alpha' : [0, 0.01, 0.1, 0.5, 0.8, 1]\n",
    "    }), \n",
    "    (RandomForestClassifier(), {\n",
    "        'model__class_weight' : ['balanced', None],\n",
    "        'model__n_estimators' : [10, 100, 1000],\n",
    "        'model__ccp_alpha' : [0, 0.01, 0.1]\n",
    "    }), \n",
    "    (XGBClassifier(eval_metric='logloss', use_label_encoder=False), {\n",
    "        'model__scale_pos_weight' : [1, 10],\n",
    "        'model__max_depth' : [2, 6, 10],\n",
    "        'model__eta' : [0.01, 0.3, 0.6]\n",
    "    })\n",
    "]\n",
    "\n",
    "# Do a grid search cross validation over the parameter grid for each model, and print the results \n",
    "for model in model_list:\n",
    "    \n",
    "    pipe = Pipeline([('bow', CountVectorizer(min_df=2)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('model', model[0])])\n",
    "    param_grid = {\n",
    "        'bow__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'tfidf__norm': ['l1', 'l2'],\n",
    "    }\n",
    "    param_grid.update(model[1])\n",
    "    \n",
    "    clf = GridSearchCV(pipe, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(str(model[0]).split('(')[0])\n",
    "    print(clf.best_params_)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models have fairly similar performance. Some have slightly higher precision or recall or accuracy, so it depends on what we're going for. In this case, I would like to use the Logistic Regression model, as it requires far less computational overhead to scale to the rest of the data. \n",
    "\n",
    "Now, let's go ahead and use 50% of the data to train a Logistic Regression prototype model, and let's perform hyperparameter optimization over a larger space with randomized search cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many unseen rows to pull out of X_big to scale X_small up to 50% of total data \n",
    "sample_size = ((len(X_small) + len(X_big)) // 2) - len(X_small)\n",
    "X_new = X_big.sample(sample_size).sort_index()\n",
    "y_new = y_big[y_big.index.isin(X_new.index)].sort_index()\n",
    "\n",
    "# Append new rows to X_small and y_small\n",
    "X = X_small.append(X_new)\n",
    "y = y_small.append(y_new)\n",
    "\n",
    "# Get remaining unseen rows\n",
    "X_unseen = X_big[~X_big.index.isin(X_new.index)].sort_index()\n",
    "y_unseen = y_big[~y_big.index.isin(y_new.index)].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training split of the subsample has 48216 data points.\n",
      "The test split of the subsample has 12055 data points.\n"
     ]
    }
   ],
   "source": [
    "# Split subsample into training and test sets. \n",
    "# Once again, we use a stratified split. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "print(f'The training split of the subsample has {len(X_train)} data points.')\n",
    "print(f'The test split of the subsample has {len(X_test)} data points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.67281304        nan 0.67797219        nan 0.68077976 0.61206739\n",
      " 0.70866823 0.67846125 0.69348996 0.70051624]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "{'bow__ngram_range': (1, 2), 'model__C': 5.974598940642741, 'model__class_weight': None, 'model__max_iter': 885, 'model__penalty': 'l1', 'model__solver': 'liblinear', 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     11233\n",
      "           1       0.60      0.41      0.48       822\n",
      "\n",
      "    accuracy                           0.94     12055\n",
      "   macro avg       0.78      0.69      0.73     12055\n",
      "weighted avg       0.93      0.94      0.94     12055\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train using RandomizedSearchCV \n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipe = Pipeline([('bow', CountVectorizer(min_df=2)),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "                 \n",
    "distributions = {\n",
    "    'bow__ngram_range' : [(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__use_idf' : [True, False],\n",
    "    'tfidf__norm' : ['l1', 'l2'],\n",
    "    'model__solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'model__penalty' : ['l1', 'l2', 'none'],\n",
    "    'model__C' : uniform(loc=0, scale=10),\n",
    "    'model__max_iter': range(100, 1000),\n",
    "    'model__class_weight' : ['balanced', None]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(pipe, distributions, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Score model on test set and print best parameters \n",
    "print('Logistic Regression')\n",
    "print(clf.best_params_)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll try both oversampling and undersampling to see if it improves model performance. First, let's start with oversampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.96635193        nan        nan 0.96524874 0.96927007 0.9804519\n",
      "        nan 0.98998323 0.97053069 0.9743018 ]\n",
      "  category=UserWarning\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Oversampling)\n",
      "{'bow__ngram_range': (1, 2), 'model__C': 4.088818197618195, 'model__class_weight': None, 'model__max_iter': 751, 'model__penalty': 'none', 'model__solver': 'newton-cg', 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     11233\n",
      "           1       0.60      0.32      0.41       822\n",
      "\n",
      "    accuracy                           0.94     12055\n",
      "   macro avg       0.78      0.65      0.69     12055\n",
      "weighted avg       0.93      0.94      0.93     12055\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Reformat training data\n",
    "X_train = X_train.values.reshape(-1,1)\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "\n",
    "# Oversample training data \n",
    "oversampler = RandomOverSampler()\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reformat oversampled data\n",
    "X_train_over = pd.Series(X_train_over.squeeze())\n",
    "y_train_over = pd.Series(y_train_over.squeeze())\n",
    "\n",
    "clf_over = RandomizedSearchCV(pipe, distributions, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "clf_over.fit(X_train_over, y_train_over)\n",
    "y_pred = clf_over.predict(X_test)\n",
    "\n",
    "# Score model on test set and print best parameters \n",
    "print('Logistic Regression (Oversampling)')\n",
    "print(clf_over.best_params_)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Undersampling)\n",
      "{'bow__ngram_range': (1, 1), 'model__C': 1.8213657528887306, 'model__class_weight': 'balanced', 'model__max_iter': 833, 'model__penalty': 'l2', 'model__solver': 'saga', 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89     11233\n",
      "           1       0.23      0.78      0.36       822\n",
      "\n",
      "    accuracy                           0.81     12055\n",
      "   macro avg       0.61      0.80      0.62     12055\n",
      "weighted avg       0.93      0.81      0.85     12055\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan 0.7788026  0.77842371 0.55487683        nan 0.76976883\n",
      " 0.70952062 0.70690382 0.55424465        nan]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Oversample training data \n",
    "undersampler = RandomUnderSampler()\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reformat undersampled\n",
    "X_train_under = pd.Series(X_train_under.squeeze())\n",
    "y_train_under = pd.Series(y_train_under.squeeze())\n",
    "\n",
    "clf_under = RandomizedSearchCV(pipe, distributions, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "clf_under.fit(X_train_under, y_train_under)\n",
    "y_pred = clf_under.predict(X_test)\n",
    "\n",
    "# Score model on test set and print best parameters \n",
    "print('Logistic Regression (Undersampling)')\n",
    "print(clf_under.best_params_)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the best method is to not use any resampling at all! Let's explore what happens when we change the decision threshold of our prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     11233\n",
      "           1       0.60      0.41      0.48       822\n",
      "\n",
      "    accuracy                           0.94     12055\n",
      "   macro avg       0.78      0.69      0.73     12055\n",
      "weighted avg       0.93      0.94      0.94     12055\n",
      "\n",
      "\n",
      "Threshold 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     11233\n",
      "           1       0.81      0.25      0.38       822\n",
      "\n",
      "    accuracy                           0.94     12055\n",
      "   macro avg       0.88      0.62      0.68     12055\n",
      "weighted avg       0.94      0.94      0.93     12055\n",
      "\n",
      "\n",
      "Threshold 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94     11233\n",
      "           1       0.34      0.63      0.44       822\n",
      "\n",
      "    accuracy                           0.89     12055\n",
      "   macro avg       0.65      0.77      0.69     12055\n",
      "weighted avg       0.93      0.89      0.91     12055\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(X_test)[:,1] > 0.5\n",
    "print('Threshold 0.5')\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print()\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)[:,1] > 0.9\n",
    "print('Threshold 0.9')\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print()\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)[:,1] > 0.1\n",
    "print('Threshold 0.1')\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these metrics, may want to set a high threshold (like 0.9) to get greater precision, even if the recall decreases. This is because we really want to avoid a false positive (i.e. accusing someone of hate speech when there isn't any). With a threshold of 0.9, our model identified a fourth of all hate tweets in the test set with 81% precision! In the final application, we may just return the probabilistic predictions anyway. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll train the model on 75% of the entire dataset, and evaluate it on the remaining 25%. Afterwards, we'll train the model on the entire test set so it's ready for deployment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull from unseen data to create test set that uses 25% of all data \n",
    "test_size = len(X_unseen) // 2\n",
    "X_test = X_unseen.sample(test_size).sort_index()\n",
    "y_test = y_unseen[y_unseen.index.isin(X_test.index)].sort_index()\n",
    "\n",
    "# Get remaining unseen data \n",
    "X_unseen = X_unseen[~X_unseen.index.isin(X_test.index)].sort_index()\n",
    "y_unseen = y_unseen[~y_unseen.index.isin(y_test.index)].sort_index()\n",
    "\n",
    "# Append unseen rows to X & y to create training sets\n",
    "X_train = X.append(X_unseen)\n",
    "y_train = y.append(y_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training split of the subsample has 90407 data points.\n",
      "The test split of the subsample has 30135 data points.\n"
     ]
    }
   ],
   "source": [
    "print(f'The training split of the subsample has {len(X_train)} data points.')\n",
    "print(f'The test split of the subsample has {len(X_test)} data points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.70571054 0.666718   0.69812349 0.65997479        nan        nan\n",
      " 0.56118615 0.62405842 0.55578837 0.62492922]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Scaled)\n",
      "{'bow__ngram_range': (1, 2), 'model__C': 3.594267903050815, 'model__class_weight': None, 'model__max_iter': 988, 'model__penalty': 'l2', 'model__solver': 'saga', 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     28065\n",
      "           1       0.77      0.34      0.47      2070\n",
      "\n",
      "    accuracy                           0.95     30135\n",
      "   macro avg       0.86      0.67      0.72     30135\n",
      "weighted avg       0.94      0.95      0.94     30135\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scale the model by training on 75% of all data \n",
    "clf = RandomizedSearchCV(pipe, distributions, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Score model on test set and print best parameters \n",
    "print('Logistic Regression (Scaled)')\n",
    "print(clf.best_params_)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to prepare the model for deployment, we train it using all of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70744058 0.70047674 0.6401964         nan\n",
      " 0.54365524        nan        nan 0.72357878]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (All Data)\n",
      "{'bow__ngram_range': (1, 1), 'model__C': 9.076851334818326, 'model__class_weight': None, 'model__max_iter': 297, 'model__penalty': 'l1', 'model__solver': 'saga', 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test sets\n",
    "X = X_train.append(X_test)\n",
    "y = y_train.append(y_test)\n",
    "\n",
    "# Train model on all the data\n",
    "clf = RandomizedSearchCV(pipe, distributions, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "clf.fit(X, y);\n",
    "\n",
    "# Print final parameters\n",
    "print('Logistic Regression (All Data)')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the model\n",
    "import pickle\n",
    "pickle.dump(clf, open('model.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
